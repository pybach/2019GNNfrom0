# 課題提出物説明

## ファイルの概要
- `src/`ディレクトリ下に、`task1.py`、`task2.py`、`task3.py`、`task4a.py`、`task4b.py`の5ファイル（Pythonスクリプト）が置かれています。

- 番号がそれぞれ課題番号に対応します。例えば課題3は`task3.py`で行っています。

- 課題4のみ、2ファイルに分かれています。`task4a.py`はAdamの実装、`task4b.py`は多層ニューラルネット化を行っています。

- 全てPython3で書かれています。動作確認はmacOS Sierra上にpyenvでインストールしたPython 3.7.0で行いました（Matplotlib 3.0.3, Numpy 1.16.3）。  
（なお、この環境のデフォルトで実行するとMatplotlibに関するエラーが発生し、matplotlibrc中の`backend : macosx`を`backend : Tkagg`に修正する必要がありました。）

- インポートするパッケージはmath、numpy、matplotlibの3つです。

- 各ファイルを直接、`$ python task1.py`
のように実行すると各課題のテストプログラムが走ります。

- テストプログラムは、データセットがスクリプトから見て`../../datasets/`以下に置かれている（`datasets/`が、本ファイル`README.md`の置かれているディレクトリの兄弟ディレクトリである）ことを想定して書かれています。

- `task4a.py`と`task4b.py`は`task3.py`を、`task3.py`は`task2.py`を、`task2.py`は`task1.py`を、それぞれ内部でインポートします。

- コード内容の説明は、ソースコード中にコメントとして直接書かれています。

## 内容および実行結果に関する説明
- 本回答では、まず課題1でクラス`GNN1`を定義します。次いで課題2でその派生クラス`GNN2`、さらに課題3で`GNN3`といったように、順に継承して機能を追加していきます。上記の依存関係があるのはそのためです。

- GNNクラスの他に、`task3.py`と`task4a.py`では、(momentum)SGDやAdamを実現するためのオプティマイザクラスを定義しています。

- `task1.py`を実行すると、問題文冒頭に例示されているグラフ`G`に対して、`D=3`の適当な`W`で`T`を`0`から`2`まで変化させた場合の`GNN1.readout(G)`の結果が表示されます。

- `task2.py`を実行すると、与えられているラベル付きデータセットの中からランダムに1組を選び、勾配降下学習を32ステップまで行います。選んだ組の番号と、各ステップでの損失関数の値を表示します。結果から、損失関数の値が毎回確かに減少していることを確認できます。

- `task3.py`を実行すると、データセット2000組のうち1600組を学習用、400組を検証用として、SGDおよびmomentum SGDによるミニバッチ学習（バッチサイズ16）をそれぞれ10エポックまで行います。  
学習過程での損失および正答率の履歴を`task3_losses.npz`に、学習済みパラメータ値を`task3_theta.npz`に、学習曲線のプロット図を`task3_plot.pdf`に、それぞれ保存します。

- `task4a.py`の実行結果は`task3.py`と同様ですが、さらにAdamの結果が加わります。またエポック数は30としています。  
保存されるファイルはそれぞれ`task4a_losses.npz`、`task4a_theta.npz`、`task4a_plot.pdf`です。

- `task4b.py`は、同様の学習で従来の単層ネットワーク`GNN3`と、多層化したネットワーク`GNN4`のパフォーマンス比較を行うものです。最適化アルゴリズムはmomentum SGDに統一しています。  
保存されるファイルはそれぞれ`task4b_losses.npz`、`task4b_theta.npz`、`task4b_plot.pdf`です。
